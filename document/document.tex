% !TEX TS-program = lualatex
%%%%%%%%%%%%%%%%%% USAGE INSTRUCTIONS %%%%%%%%%%%%%%%%%%
% - Compile using LuaLaTeX and biber, unless there is a particular reason not to. Do not use the older LaTex/PDFLaTeX or BibTeX. (The fonts won't work correctly.)
% - Expect to get 2 warnings when working correctly, one on xcolor and hyperref, and one on ExtSizes saying is better to use a class. These can be ignored.
% - Font and the report 'year' must be specified when all \documentclass or the template won't work correctly. (There's no error checking/default cases!)
% - For best performance save images/graphics as PDF files, not as png/jpg/eps. This makes no difference to how images are inserted using \includegraphics.
% - As many further packages as wanted can be loaded. Below are just an example set. Note that template itself loads a number of packages, including hyperref.
% - References are handed using biblatex.
% - Link to the presentation of dissertations policy: https://documents.manchester.ac.uk/display.aspx?DocID=2863



%%%%%%%%%%%%%%%%%% META DATA SETUP %%%%%%%%%%%%%%%%%%
% This is where the document title and author are set. Other details for the title page are set later
% Note that if/when you edit these you may need to 'Recompile from scratch' to get the changes to display in the PDF. (In Overleaf, select the down arrow to the right of the 'Recompile' button)
\begin{filecontents*}{\jobname.xmpdata}
  \Title{BEng final dissertation} 
  \Author{11006231} % should be student number rather than name to help with annoymous marking
  \Language{en-GB}
  \Copyrighted{True}
  % More meta-data fielda can be added here if wanted, see https://ctan.org/pkg/pdfx?lang=en for fields
\end{filecontents*}

\newcommand{\newtitle}{Human Teleoperation of a Laterally Mounted Robot Arm}
\newcommand{\mystudentid}{11006231}

%%%%%%%%%%%%%%%%%% DOCUMENT SETUP %%%%%%%%%%%%%%%%%%
\documentclass[12pt,beng]{uom_eee_dissertation_casson} % course can be msc or beng
% Check your course handbook for the correct font size to use. Make sure this is correct - you may get an overlength penalty if not! Is currently 12 for BEng, and 11 for MSc. The template doesn't change this automatically for you


%%%%%%%%%%%%%%%%%% PACKAGES AND COMMANDS %%%%%%%%%%%%%%%%%%

% Packages
\usepackage{graphicx}              % for adding graphics files
  \graphicspath{ {./images/} }
\usepackage{amsmath}               % assumes amsmath package installed
  \allowdisplaybreaks[1]           % allow eqnarrays to break across pages
\usepackage{amssymb}               % assumes amsmath package installed 
\usepackage{url}                   % format hyperlinks correctly
\usepackage{rotating}              % allow portrait figures and tables
\usepackage{multirow}              % allows merging of rows in tables
\usepackage{lscape}                % allows pages to be typeset in landscape mode
\usepackage{tabularx}              % allows fixed width tables
\usepackage{verbatim}              % enhanced version of built-in verbatim environment
\usepackage{footnote}              % allows more control over footnote environments
\usepackage{float}                 % allows H option on floats to force here placement
\usepackage{booktabs}              % improve table line spacing
\usepackage{lipsum}                % for adding dummy text here
\usepackage[base]{babel}           % required for lisum package
\usepackage{subcaption}            % for multiple sub-figures in a single float
\usepackage{siunitx}               % add SI units
% Add your packages here


% Custom commands
\newcommand{\degree}{\ensuremath{^\circ}}
\newcommand{\sus}[1]{$^{\mbox{\scriptsize #1}}$} % superscript in text (e.g. 1st)
\newcommand{\sub}[1]{$_{\mbox{\scriptsize #1}}$} % subscript in text
\newcommand{\otoprule}{\midrule[\heavyrulewidth]}
\newcolumntype{Z}{>{\centering\arraybackslash}X}  % tabularx centered columns 
% Add your custom commands here



%%%%%%%%%%%%%%%%%% REFERENCES SETUP %%%%%%%%%%%%%%%%%%

% Setup your references here. Change the reference style here if wanted
\usepackage[style=ieee,backend=biber,backref=true,hyperref=auto,maxbibnames=3,minbibnames=1]{biblatex}
% Note backref=true adds a page number (and hyperlink) to each reference so you can easily go back from the references to the main document. You may prefer backref=false if you need to stick strictly to a given reference style


% Fixes which can't be applied in the .cls file
\DefineBibliographyStrings{english}{backrefpage = {cited on p\adddot},  backrefpages = {cited on pp\adddot}}
%  \renewcommand*{\bibfont}{\large}


% Add more .bib files here if wanted
\addbibresource{references.bib}



%%%%%%%%%%%%%%%%%% AUTOMATIC WORD COUNT SETUP %%%%%%%%%%%%%%%%%%
% Automatically counts the words present and makes a \mywordcount variable. This is used later to automatically add the word count (which can be overridden if wanted)
% See https://www.overleaf.com/learn/how-to/Is_there_a_way_to_run_a_word_count_that_doesn%27t_include_LaTeX_commands%3F for info on what words are counted and how to control this. Any changes to what's counted need to be made in uom_thesis_casson.cls, in the \newcommand{\quickwordcount} command. The default doesn't count words in headings, captions, or references and so you may get slightly different numbers if use a different word count tool
% This can be a bit fragile. If it doesn't work, there's an option later on to just type in a numer
% \quickwordcount{\currfilebase} % run word count. This just counts the words. Is displayed with the \wordcount command later



%%%%%%%%%%%%%%%%%% START DOCUMENT %%%%%%%%%%%%%%%%%%

% Don't edit these lines, title and author are automatically taken from the document meta-data defined above
\begin{document}
\makeatletter
\title{\newtitle}
\studentid{\mystudentid}
\makeatother

% Set the below yourself
\course{Electronic Engineering}  % "Master of Science in" or "Bachelor of Engineering in "
                                                   % is added automatically
                                                   % Our BEng courses are: Electrical and Electronic Engineering, Electrical Engineering, and Mechatronic Engineering
                                                   % Our MSc courses are: Advanced Control and Systems Engineering, Advanced Control and Systems Engineering with Extended Research, Communications and Signal Processing, Communications and Signal Processing with Extended Research, Electrical Power Systems Engineering, Advanced Electrical Power Systems Engineering, Renewable Energy and Clean Technology, Renewable Energy and Clean Technology with Extended Research, Robotics, Robotics with Extended Research
\faculty{Science and Engineering}                  % "Faculty of" is added automatically
\school{School of Engineering} % "School of" not added automatically (as if in AMBS, School comes at the end rather than the start), so enter full name of School here
\submitdate{2025}                                  % regulations ask only for the year, not month
\wordcount{\mywordcount}		                   % use \wordcount{} to set the count. Can just type in a number (e.g. \wordcount{1000}	if don't want to use the automatic count.) This is automatically displayed after the table of contents. 
\maketitle



%%%%%%%%%%%%%%%%%% LISTS OF CONTENT %%%%%%%%%%%%%%%%%%
\uomtoc
% other lists are not required, but can include \uomlof and \uomlot if really want to


%%%%%%%%%%%%%%%%%% ABSTRACT %%%%%%%%%%%%%%%%%%
\begin{abstract} % put abstract here.
  This is abstract text. 
  
  \lipsum[1-2]
\end{abstract}%
\clearpage



%%%%%%%%%%%%%%%%%% DECLARATIONS %%%%%%%%%%%%%%%%%%
\begin{uomoriginality}
  \uomoriginalitydeclaration 
  % If the standard originality decalaration is sufficient, saying no portion of the work has been submitted in support of an application for another degree or qualification, the above command will automatically add the required text and nothing else is needed in this section.
  % If the standard statment isn't sufficient, then comment out the \uomoriginalitydeclaration command and type in your own text here explaining the authorship of any re-used portions. 
\end{uomoriginality}
\uomcopyrightstatement



%%%%%%%%%%%%%%%%%% ACKNOWLEDGEMENTS %%%%%%%%%%%%%%%%%%
\begin{uomacknowledgements}
Acknowledgments go here.
\end{uomacknowledgements}



%%%%%%%%%%%%%%%%%% Start content %%%%%%%%%%%%%%%%%%
\uomstartmainbody % Don't delete. used to flag to the hyperlinks in the PDF that the main content is  starting



%%%%%%%%%%%%%%%%%% INTRODUCTION %%%%%%%%%%%%%%%%%%
\section{Introduction} % can use \input{} or \include{} for each section to draw content from other files rather than having everything in one big file
  
  The goal of this project is to create a system for controlling and teleoperating a robot arm with a human arm. 
  In order to maintain simplicity in the project scope, the robot arm is assumed to be shoulder-mounted and has the seven degrees of freedom (DoF) \cite{ref:arm_dofs}, matching that of a healthy human arm.

  \subsection{Background and motivation}
  The motivation for this project comes from articles within the books: \citetitle{ref:Zhou_Yang_Wang_Dong_2025} \cite{ref:Zhou_Yang_Wang_Dong_2025} and \citetitle{ref:Lyu_Yang_Yang_2025} \cite{ref:Lyu_Yang_Yang_2025}, which both describe research into remote teleoperation of shoulder-mounted robot arms.
  Both articles describe the use of an inertial measurement unit (IMU) based solution to obtain data from the human operator.
  The limitation in both of these articles is that they only map the end effector position of the robot arm to the wrist position.
  Because the human arm has redundancy in the number of joints available \cite{ref:nullspace}, a robot arm only mapping the end effector position could end up with its forearm or upper arm in a position that causes collisions, even though the end effector is in the target position.  
  This ambiguity could lead to collisions with obstacles in the environment, and lack of safety for people within the envelope of the robot arm. 
  
  Whilst not necessarily critical in the use cases that \citeauthor{ref:Zhou_Yang_Wang_Dong_2025} and \citeauthor{ref:Lyu_Yang_Yang_2025} describe - remote welding inspection and simple delivery and manipulation tasks for an elderly patient - a scenario that is obstacle rich would require precise control of the robot arm.
  One such scenario is an underwater environment where a telescopic robot arm is attempting to collect a sample.
  Whilst \citeauthor{ref:Jin_Ji_Yan_2023} describes a potential autonomous solution \cite{ref:Jin_Ji_Yan_2023}, this method is comparatively slow to the prospect of remote teleoperation: ranging from five to nine seconds in the simple case where the target object and origin of the robot arm is stationary.
  Consequently, the complexity increase for the case where nothing is stationary, a more realistic use case, would mean that this method would be inefficient compared to the intuition of a trained operator. 
  Additionally, \citeauthor{ref:vranalysis} shows that for tasks involving teleoperation of a robot for pick and place tasks, virtual reality style mapping of head movements with arm to end effector mapping is more efficient and less error prone than a typical joystick \cite{ref:vranalysis}.

  Other potential areas of application of full arm tracking could be in the medical industry and with surgical robots, where collisions with patients is unwanted. 
  Likewise, nuclear decommissioning robots where absolute accuracy of matching an operator's intentions is critical.

  \subsection{Aims and objectives}
  The overall aim is to create a system for mapping the joint angles of a human arm to a shoulder-mounted robot arm.

  To achieve this goal, there will be an evaluation of available arm tracking methods. 
  Many methods currently exist for tracking the joint angles of robot arms, including: IMU based solutions discussed earlier, attitude and heading reference systems \cite{ref:Mazomenos_Biswas_Cranny_Rajan_Maharatna_Achner_Klemke_Jobges_Ortmann_Langendorfer_2016}, computer vision based systems \cite{ref:Phuong_Cong_2024}, and flex sensor based systems \cite{ref:Nalam_Manivannan_2014}, among others.
  A rigorous examination of these methods will be conducted as a prerequisite to the final implementation, to understand the applicability and feasibility of each tracking system.
  Relevant tracking metrics will be discussed in the literature review, but include factors such as cost, accuracy, engineering complexity, etc.
  These metrics have been selected in order to allow for the feasible completion of this project given the time, scope and availability of resources for the final year project. 

  Finally, it is acknowledged that the procurement of a seven DoF robot arm is unlikely for a Bachelor's thesis. 
  Hence, the final implementation of the tracking method will be created in the form of a simulation in CoppeliaSim.
  This has the advantage of being able to set up precise scenes for the evaluation of the final tracking method chosen, as well as comparison with baseline methods such as joysticks or pure end effector mapping.
  Likewise, the robot could be customised to match the proportions of the operator's arm perfectly, which would increase ease of use for the operator.


%%%%%%%%%%%%%%%%%% LITERATURE REVIEW %%%%%%%%%%%%%%%%%%
\section{Literature review}

  \subsection{Introduction}
    The measurement of human arm joint angles has been an interest of academia for several decades: with one of the first examples being demonstrated by \citeauthor{ref:videobasedumanmotioncapture}. 
    In industrial settings, full body tracking has primarily been used in the film industry to map an actor's performance onto computer generated characters \cite{ref:whatmocap}.
    The main advantage of this is to save time in the creation of realistic looking movements \cite{ref:mocapwhy}, as an actor is able to portray realistic and nuanced motion that gets digitised. 
    Therefore, it seems logical that one should be able to combine the two applications - have a skilled operator trained in specific movement patterns to remotely control industrial robots where traditional control methods (e.g. joysticks) are unsuitable.
    For example, in an application that compared participants performance between a purely joystick based control method, and VR control with hand tracking, tasks were completed up to \num{1.8} times faster and with a quarter of the errors (\(1.54 \% \) compared to \(8.65 \% \)) in the best cases)  \cite{ref:vranalysis}. 

    Likewise, research from \citeauthor{ref:teleopanalysis} also seems to indicate that the time to complete a novel teleoperation task was initially better when users had their head movements mapped to the control of the robot's vision systems \cite{ref:teleopanalysis}. 
    However, it is important to acknowledge that this study also showed that overall performance improved with experience between trial groups, and participants with more experience controlling the robot did better when controlling the robot via joystick.
    The overall takeaway from this is that whether or not a novel approach to teleoperation is more effective than traditional joysticks is strongly dependent on the task.
    Research conducted by \citeauthor{ref:Zhou_Yang_Wang_Dong_2025} shows that the control of a seven degree of freedom robot, could be improved via human arm teleoperation, which strengthens the justification for this project.

  \subsection{Project requirements}
    In order to compare the final system to existing systems and research, a baseline performance must be characterised.
    This has been categorised into three distinct goals for the final system: position based requirements, time based requirements and resource based requirements.
    These requirements will help to compare the existing technologies in the next subsection.
    
    Existing research into the lower bounds of human arm accuracy shows that experienced surgeons have approximately \(5 \degree\) of vertical movement range on all joints when asked to hold their hand on a target, and close to \(3 \degree\) range for horizontal movement.
    The study performed by \citeauthor{ref:movementrange} was performed with novice and expert surgeons, which would imply that this range of joint movement is above average for most humans.
    Taking this into account, the requirements are that the final system must be able to measure joint rotation in each joint up to a resolution of \(5 \degree\).
    Any movement measured less than this resolution is presumed to be 'noise' from human inaccuracy, and will therefore need to be smoothed out in the final implementation.
    This way the system is able to accurately capture the intent of the operator's movement, whilst preserving some level of accuracy.

    Similar research exists for time based requirements as well, especially in the area of latency.
    It seems intuitive that more delay in a teleoperation system will decrease performance - research suggests that this manifests itself within two key figures of \(600 \text{ms}\) and \(1500 \text{ms}\) \cite{ref:teleoplatency}.
    Task performance generally decreased with latency, with task performance falling at a latency of \(600 \text{ms}\) and any latency above \(1500 \text{ms}\) showing the most significant drop in task performance.
    Therefore the final arm tracking system should aim to measure arm angles well below the \(600 \text{ms}\) threshold.
    The Nyquist criterion equivalent of this threshold is used as a well informed estimate of how much latency can be present in the system, leaving a final requirement of \(300 \text{ms}\). 
    
    The budget for this project is £\(180\).
    This means that the final solution must be cheaper to implement than this.
    Likewise, the time to complete this project is \(30\) unit credits worth of time, equating to \(240\) hours of time commitment, excluding time required for completing written deliverables.
    Both of these factors will mean that the final solution favours simpler, more complete solutions - anything novel is a potential failure point that could mean the project does not complete.  
  \subsection{Survey of existing tracking technologies}
    In order to fully evaluate the myriad of arm tracking methods available, a Pugh Matrix has been created to evaluate and compare several factors between each method.
    Each method will score \(1 - 5\) in each category, with a brief comment justifying the score in each column.
    
    Below are the decision factors of the Pugh Matrix and a brief description of how they are scored: \begin {itemize}
      \item \textbf{Complexity} - \(1\) means that this design is unlikely to be built in the time budget of \(240\) hours, \(5\) means that this design is easily built in this time period.
      \item \textbf{Cheapness} - \(1\) means that this design cannot be achieved in the provided budget of £\(180\), \(5\) means that this design is easily achievable in this budget.
      \item \textbf{Accuracy} - This is calculated from available research on the accuracy of this method. Each multiple of \(5 \degree\) above \(5 \degree\) reduces the score by \(1\), e.g. an absolute accuracy of \(6 - 10 \degree\) would score \(4\), \(11 - 15 \degree\) would score \(3\).
      \item \textbf{Latency} - This is calculated from available research on the time it takes to obtain a single measurement of all 7 joint angles from this method. Each multiple of \(100 \text{ms}\) above \(300 \text{ms}\) reduces the score by \(1\), e.g. a latency of \(301 \text{ms} - 400 \text{ms}\) would score \(4\).
    \end{itemize}



    % \begin{figure}
    %   \centering
    %   \includegraphics[alt={Put short description for screen readers here},width=0.3\textwidth,keepaspectratio=true]{uom_logo.pdf}
    %   \caption[Short caption for list of figures]{Example figure. Full caption goes here. Often a short caption in [] is used as well as the main caption to keep the list of figures tidy; it gets messy if there are long captions going over more than one line.}
    %   \label{fig:uom_logo}
    % \end{figure} 

    % \begin{figure}
    %   \centering
    %   \begin{subfigure}{0.3\linewidth}
    %     \includegraphics[alt={Put short description for screen readers here},width=\textwidth,keepaspectratio=true]{uom_logo.pdf}
    %     \caption{}
    %     \label{fig:subfig_a}
    %   \end{subfigure}
    %   \begin{subfigure}{0.3\linewidth}
    %     \includegraphics[alt={Put short description for screen readers here},width=\textwidth,keepaspectratio=true]{uom_logo.pdf}
    %     \caption{}
    %     \label{fig:subfig_b}
    %   \end{subfigure}
    %   \begin{subfigure}{0.3\linewidth}
    %     \includegraphics[alt={Put short description for screen readers here},width=\textwidth,keepaspectratio=true]{uom_logo.pdf}
    %     \caption{}
    %     \label{fig:subfig_c}
    %  \end{subfigure}
    %  \caption{Three copies of the University logo. (a) Copy one. (b) Copy two. (c) Copy three.}
    %  \label{fig:uom_logo_in_subfig}
    % \end{figure}  
  
  
%%%%%%%%%%%%%%%%%% METHODS %%%%%%%%%%%%%%%%%%
\section{Methods} \label{sec:methods}

  \subsection{Introduction}
    \lipsum[1] % adds dummy text to fill up the example
  
  \subsection{Content} \label{sec:content}
    \subsubsection{Introduction}
      \lipsum[1] % adds dummy text to fill up the example
	
    \subsubsection{Detail}
      \lipsum[7-11] % adds dummy text to fill up the example
    
    \subsubsection{More detail}
      \lipsum[1-3] % adds dummy text to fill up the example
	
    \subsubsection{Summary}
      \lipsum[1] % adds dummy text to fill up the example
  
  \subsection{Summary}
    \lipsum[6] % adds dummy text to fill up the example



%%%%%%%%%%%%%%%%%% RESULTS %%%%%%%%%%%%%%%%%%
\section{Results and discussion} \label{sec:results}

  \subsection{Introduction}
    \lipsum[1] % adds dummy text to fill up the example
  
  \subsection{Content}
    \subsubsection{Introduction}
	\lipsum[1] % adds dummy text to fill up the example
	
	\subsubsection{Detail}
        \lipsum[7-11] % adds dummy text to fill up the example
    
	\subsubsection{More detail}
	\lipsum[1-3] % adds dummy text to fill up the example
	
	\subsubsection{Summary}
	\lipsum[1] % adds dummy text to fill up the example
  
  \subsection{Summary}
    \lipsum[6] % adds dummy text to fill up the example



%%%%%%%%%%%%%%%%%% CONCLUSIONS %%%%%%%%%%%%%%%%%%
\section{Conclusions and future work} % edit subsection heading as appropriate
    \subsection{Conclusions}
	\lipsum[1]
	
	\subsection{Future work}
    \lipsum[1-2] \cite{ref:jCAS10,ref:jCAS09,ref:jCAS09a} \lipsum[3-5]



%%%%%%%%%%%%%%%%%% REFERENCES %%%%%%%%%%%%%%%%%%
%\clearpage % uncomment to start on a new page if wanted
\printbibliography[title={References},heading=bibintoc] % a single list of references for the whole thesis



%%%%%%%%%%%%%%%%%% APPENDICES %%%%%%%%%%%%%%%%%%
\begin{uomappendix} 
    \section{Project outline}
    Project outline as submitted at the start of the project is a required appendix. Put here. 
    
    \section{Risk assessment}
    Risk assessment is a required appendix. Put here.
    
    %\subsection{Other appendices as necessary}
\end{uomappendix}


%%%%%%%%%%%%%%%%%% END MATTER %%%%%%%%%%%%%%%%%%
\end{document}